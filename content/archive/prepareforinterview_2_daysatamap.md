+++
title = "Raḥimahu Allāh"
date = 2025-05-04T12:38:52+08:00
draft = false
description = ""
subtitle = "愿真主怜悯他"
header_img = ""
short = false
toc = true
tags = []
categories = ["计算机"]
series = ["面试", "八股文"]
comment = false
summary = ""
+++

# 🎯 积分兑换系统全景总结（含同步与异步版本对比、设计哲学）
> 里程兑换又上新了。真棒。又是怀念我J总、HB老板和H哥的一天。

### 🧱 系统关键目标

* 高并发下安全的积分扣减和商品发放
* 明确交易状态，确保最终一致性
* 兼顾用户体验与系统可维护性

## 📐 核心流程图（异步落账版本，商品同步）

```text
[用户请求]
    ↓
[前置校验]（风控、兑换资格、次数）
    ↓
[积分预扣阶段（事务）]
    - 查询总表判断积分是否足够
    - Redis DECR 次数、疲劳度
    - 乐观锁扣减积分表 + 插入 right_record = prelock
        - UPDATE user_points WHERE points = 原值
        - INSERT right_record
    ↓
[调用商品服务（同步）]
    ↓
  ┌────────────┬──────────────┐
  │            │              │
成功         失败（或超时）   异常场景
  │            │              │
  ↓            ↓              ↓
[更新 right_record = pending]   [更新为 cancel + 回滚 Redis + 补偿积分表]
[发布积分核销事件]
  ↓
[异步 Worker 消费事件]
  ↓
[积分明细落账处理（事务）]
    - 删除 & 拆分明细
    - 更新 right_record = success
```

## 🔄 核心状态机（right\_record.status）

| 状态      | 含义           |
| ------- | ------------ |
| prelock | 积分预扣成功，未发货   |
| pending | 商品发货成功，积分待落账 |
| success | 核销完成，交易完成    |
| cancel  | 任意失败，整体回滚    |

## 🔍 核心设计点说明

### ✅ 1. 乐观锁的使用（积分总表）

* 查询积分后在更新时加 `WHERE points = 原值`
* 防止并发下出现双重扣减或超发
* 未命中时直接视为失败，避免锁竞争

### ✅ 2. 商品服务为什么保留同步？

* 商品发放是交易中**最关键的操作**：一旦发货不能撤回
* 异步发货会带来以下风险：

  * 无法准确确认是否发出
  * 回查接口不一定可靠
  * 需要复杂补偿逻辑
* 保留同步调用可以：

  * 明确交易分界点
  * 避免二次发货
  * 提高可控性

> ✅ Trade-off：牺牲部分吞吐换来交易确定性

### ✅ 3. 异步化为什么只做积分落账？

* 原因：明细落账是数据库中**最耗时**的操作

  * 查询 + 多条删除 + 拆分更新
* 用户感知度低（核销可晚点完成）
* 商品已发货不可撤销，因此积分落账放后异步处理

### ✅ 4. right\_record 的角色

* 交易锚点：状态全由它驱动
* 幂等保证：无论同步/异步失败后重试都可以靠它定位
* 监控与补偿：系统只需扫描 prelock / pending 记录即可

## ⚙️ 各阶段事务说明

| 阶段     | 是否事务 | 内容                                  |
| ------ | ---- | ----------------------------------- |
| 积分预扣阶段 | ✅    | Redis 扣次数（非事务） + MySQL 扣积分、插入记录（事务） |
| 商品服务调用 | ❌    | 同步调用，决定是否进入异步落账                     |
| 积分明细落账 | ✅    | 删除、拆分明细，更新状态                        |
| 回滚流程   | 部分事务 | 积分表回加（事务），Redis 回滚（非事务）             |

## 🧱 补偿机制 & 幂等处理

* 补偿扫描：right\_record where status in ('prelock', 'pending')
* 异步落账幂等处理：检查 right\_record.status 是否已为 success
* Redis 回滚失败记录：补偿任务执行 Lua 脚本自动恢复
* 商品服务失败：走 retry + cancel 路径

## 🧠 Trade-off 一览

| 决策       | 价值            | 代价                  |
| -------- | ------------- | ------------------- |
| 商品服务同步处理 | 明确交易边界，确保发货安全 | 牺牲部分吞吐              |
| 落账异步处理   | 减少用户等待，提升 RT  | 增加补偿和监控复杂度          |
| 乐观锁扣积分   | 无需锁表，抗并发强     | 需配合幂等防止重复扣减         |
| 不冻结明细    | 实现简单          | 需 fallback 容忍部分过期冲突 |

## 🔧 推荐优化路径（未来演进）

* 使用 Kafka / NSQ 替代内建 eventBus，实现跨服务可靠消费
* right\_record 支持多子状态：落账中、补偿中等
* 明细层面增加“冻结”状态，防止核销中被后台清除
* 积分总表刷新的 worker 做 checksum 与审计校验
* 引入 trace ID 全链路追踪

## ✅ 总结：这是一套精心平衡“吞吐、准确性、可控性”的积分系统架构

* 发货必须成功 → 同步，确认边界
* 落账可以稍后 → 异步，提升性能
* 异步机制 + 状态机 + 幂等机制确保最终一致
* 整体设计允许局部故障，但能最终收敛、可补偿


# 🎯 高并发、低延迟、99.99%可用的弹幕系统设计方案
> 这面试官长得可真像QHY，怀念我曾经好兄弟的一天。

## 一、目标与挑战

- 支持百万级并发连接，低延迟实时消息传输
- 架构具备高可用、易扩展、易维护
- 核心关注推送链路（接收弹幕）性能与稳定性

## 二、整体架构简述（逻辑层次）

1. **客户端 WebSocket 长连接接入**
2. **WebSocket 网关负责连接池管理和消息推送**
3. **发弹幕走普通业务链路（HTTP / RPC）**
4. **业务服务处理逻辑、异步持久化、消息入队**
5. **消息队列（MQ）做弹幕广播中转**
6. **推送服务消费 MQ 消息，按房间广播推送**

## 三、链路设计

### 1. 发弹幕链路（客户端 → 服务端）
- 客户端发弹幕使用 HTTP / RPC 请求
- 业务服务校验 + 异步写库 + 投递到 MQ

### 2. 弹幕广播链路（服务端 → 客户端）
- MQ 作为消息中心（Kafka / 内存 MQ）
- 推送服务消费后 fanout 到房间内用户
- 网关根据房间连接列表，将消息通过 WebSocket 推送

## 四、关键模块设计

### WebSocket 网关
- 长连接维护，支持水平扩展（如 Redis + 一致性哈希）

### 消息队列（MQ）
- 每个房间一个逻辑 Topic，支持批量、压缩、高吞吐

### 推送服务
- 消费 MQ 消息，批量广播到活跃连接

## 五、性能与可用性优化

| 优化点 | 策略 |
|--------|------|
| 发弹幕延迟 | 异步落库 |
| 广播效率 | 批量推送、合并帧 |
| 高可用性 | 多实例部署，跨 AZ 容灾 |

## 六、设计取舍说明：发弹幕为何不走 WebSocket？

- 单用户发弹幕为低频操作，适合走 HTTP 请求
- WebSocket 专注于广播推送链路，职责更清晰
- 便于限流、鉴权、打点等通用请求控制策略

## 🎙️ 七、精华答题版（2 分钟表达）

我会把弹幕系统分为两个核心链路：**发弹幕**和**推弹幕**。

- 发弹幕我采用常规的 **HTTP/RPC 链路**，因为用户发弹幕是低频行为，不需要长连接，走短链路更适合做限流、鉴权、埋点，也易于维护。
  
- 推弹幕走 **WebSocket + 消息队列（MQ）链路**。客户端与网关维持长连接，服务端通过业务逻辑将弹幕写入 MQ，推送服务按房间消费后，fanout 给所有在线用户。这样能实现毫秒级推送。

- 架构上我做了解耦：客户端连网关，业务服务异步处理并落库，推送层独立消费推送。WebSocket 网关支持水平扩展，通过连接状态表或 Redis 路由。

- 为了高可用，所有服务都可无状态部署，多实例部署在多机房，结合心跳、重连机制和状态热备保证整体 SLA。

这种设计能保证大规模并发下的 **低延迟、稳定性与弹性扩展性**，同时逻辑清晰，职责划分明确，适合生产环境落地。

